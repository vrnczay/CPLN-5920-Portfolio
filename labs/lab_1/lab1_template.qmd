---
title: "Lab 1: Census Data Quality for Policy Decisions"
subtitle: "Evaluating Data Reliability for Algorithmic Decision-Making"
author: "Your Name Here"
date: today
format: 
  html:
    code-fold: false
    toc: true
    toc-location: left
    theme: cosmo
execute:
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

# Assignment Overview

## Scenario

You are a data analyst for the **California Department of Human Services**. The department is considering implementing an algorithmic system to identify communities that should receive priority for social service funding and outreach programs. Your supervisor has asked you to evaluate the quality and reliability of available census data to inform this decision.

Drawing on our Week 2 discussion of algorithmic bias, you need to assess not just what the data shows, but how reliable it is and what communities might be affected by data quality issues.

## Learning Objectives

-   Apply dplyr functions to real census data for policy analysis
-   Evaluate data quality using margins of error
-   Connect technical analysis to algorithmic decision-making
-   Identify potential equity implications of data reliability issues
-   Create professional documentation for policy stakeholders

## Submission Instructions

**Submit by posting your updated portfolio link on Canvas.** Your assignment should be accessible at `your-portfolio-url/labs/lab_1/`

Make sure to update your `_quarto.yml` navigation to include this assignment under an "Labs" menu.

# Part 1: Portfolio Integration

Create this assignment in your portfolio repository under an `labs/lab_1/` folder structure. Update your navigation menu to include:

```         
- text: Assignments
  menu:
    - href: labs/lab_1/your_file_name.qmd
      text: "Lab 1: Census Data Exploration"
```

If there is a special character like a colon, you need use double quote mark so that the quarto can identify this as text 

# Setup

```{r setup}
# Load required packages (hint: you need tidycensus, tidyverse, and knitr)
library(tidycensus)
library(tidyverse)
library(knitr)
# Set your Census API key
census_api_key("1580dabad835478ae3a677b86254a17c8e2ce894")

# Choose your state for analysis - assign it to a variable called my_state
my_state <- "California"
```

**State Selection:** I have chosen **California** for this analysis because: I lived in California for 3 years. Also, it has a very diverse population. California includes many large cities, suburban areas, and rural regions, which allows me to see differences between places.

# Part 2: County-Level Resource Assessment

## 2.1 Data Retrieval

**Your Task:** Use `get_acs()` to retrieve county-level data for your chosen state.

**Requirements:** - Geography: county level - Variables: median household income (B19013_001) and total population (B01003_001)
- Year: 2022 - Survey: acs5 - Output format: wide

**Hint:** Remember to give your variables descriptive names using the`variables = c(name = "code")` syntax.

```{r county-data}
# Write your get_acs() code here
CA_data <- get_acs(
  geography = "county",
  state = my_state,
  variables = c(
    median_hh_income = "B19013_001",
    total_population = "B01003_001"
  ),
  year = 2022,
  survey = "acs5",
  output="wide"
)

# Clean the county names to remove state name and "County" 
# Hint: use mutate() with str_remove()
CA_clean <- CA_data %>%
  mutate(
    county = NAME %>%
      str_remove(",\\s*California$") %>% 
      str_remove("\\s*County$")
  )


# Display the first few rows
head(CA_clean)

```

## 2.2 Data Quality Assessment

**Your Task:** Calculate margin of error percentages and create reliability categories.

**Requirements:** - Calculate MOE percentage: (margin of error / estimate) * 100 - Create reliability categories:
- High Confidence: MOE < 5%  
- Moderate Confidence: MOE 5-10%
- Low Confidence: MOE > 10% 
- Create a flag for unreliable estimates (MOE > 10%)

**Hint:** Use `mutate()` with `case_when()` for the categories.

```{r income-reliability}
# Calculate MOE percentage and reliability categories using mutate()
CA_data_quality <- CA_clean %>%
  mutate(
    # MOE percentage
    income_moe_pct = ((median_hh_incomeM / median_hh_incomeE) * 100),

    # reliability
    income_reliability = case_when(
      income_moe_pct < 5 ~ "High Confidence",
      income_moe_pct >= 5 & income_moe_pct <= 10 ~ "Moderate Confidence",
      income_moe_pct > 10 ~ "Low Confidence"
    ),

    # Flag unreliable
    income_unreliable = income_moe_pct > 10
  )
# Create a summary showing count of counties in each reliability category
# Hint: use count() and mutate() to add percentages
income_reliability_summary <- CA_data_quality %>%
  count(income_reliability) %>%
  mutate(percent = round(n / sum(n) * 100, 1))

```

## 2.3 High Uncertainty Counties

**Your Task:** Identify the 5 counties with the highest MOE percentages.

**Requirements:** - Sort by MOE percentage (highest first) - Select the top 5 counties - Display: county name, median income, margin of error, MOE percentage, reliability category - Format as a professional table using `kable()`

**Hint:** Use `arrange()`, `slice()`, and `select()` functions.

```{r high-uncertainty}
# Create table of top 5 counties by MOE percentage
high_uncertainty <- CA_data_quality %>%
  arrange(desc(income_moe_pct)) %>%
  slice(1:5) %>%
  select(
    county,
    median_hh_incomeE,
    median_hh_incomeM,
    income_moe_pct,
    income_reliability
  )
# Format as table with kable() - include appropriate column names and caption
high_uncertainty %>%
  kable(
    col.names = c("County", "Median Income", "Margin of Error", "MOE (%)", "Reliability Category"),
    caption = "Top 5 California Counties with Highest MOE Percentage (Median Household Income, ACS 2022 5-year)"
  )
```

**Data Quality Commentary:**

The results show that Mono, Alpine, Sierra, Trinity, and Plumas have high MOE percentages, so these counties' median income values are less reliable and they might be poorly served by algorithms that rely on this income data. Higher uncertainty can come from small population size in rural areas.

# Part 3: Neighborhood-Level Analysis

## 3.1 Focus Area Selection

**Your Task:** Select 2-3 counties from your reliability analysis for detailed tract-level study.

**Strategy:** Choose counties that represent different reliability levels (e.g., 1 high confidence, 1 moderate, 1 low confidence) to compare how data quality varies.

```{r select-counties}
# Use filter() to select 2-3 counties from your county_reliability data
# Store the selected counties in a variable called selected_counties

selected_counties <- bind_rows(
  CA_data_quality %>%
    filter(income_reliability == "High Confidence") %>%
    sample_n(1),

  CA_data_quality %>%
    filter(income_reliability == "Moderate Confidence") %>%
    sample_n(1),

  CA_data_quality %>%
    filter(income_reliability == "Low Confidence") %>%
    sample_n(1),
)
set.seed(123)

# Display the selected counties with their key characteristics
# Show: county name, median income, MOE percentage, reliability category
selected_counties %>%
  select(
    county,
    median_hh_incomeE,
    median_hh_incomeM,
    income_moe_pct,
    income_reliability
  ) %>%
  kable(
    col.names = c("County", "Median Income", "Margin of Error", "MOE (%)", "Reliability Category"),
    caption = "Selected California Counties for Tract-Level Study in Different Reliability Levels"
  )

```

**Comment on the output:** The three counties represent different levels of data reliability. I used random selection within each reliability category to choose one county, and I set a seed to allow program to memorize the selection. This means I get the same three counties each time I run the code. This process reduces selection bias and to make the output reproducible.

## 3.2 Tract-Level Demographics

**Your Task:** Get demographic data for census tracts in your selected counties.

**Requirements:** 
- Geography: tract level 
- Variables: white alone (B03002_003), Black/African American (B03002_004), Hispanic/Latino (B03002_012), total population (B03002_001)
- Use the same state and year as before 
- Output format: wide 
- **Challenge:** You'll need county codes, not names. Look at the GEOID patterns in your county data for hints.

```{r tract-demographics}
# Define your race/ethnicity variables with descriptive names
CA_race <- c(
  total_pop = "B03002_001",
  white = "B03002_003",
  black = "B03002_004",
  hispanic = "B03002_012"
)
CA_county_codes <- selected_counties %>%
  mutate(county_fips = str_sub(GEOID, 3, 5)) %>%   # take the 3-digit county code
  pull(county_fips)
# Use get_acs() to retrieve tract-level data
# Hint: You may need to specify county codes in the county parameter
CA_race_tract <- get_acs(
  geography="tract",
  state=my_state,
  county= CA_county_codes,
  variables=CA_race,
  year=2022,
  survey="acs5",
  output="wide"
)

# Calculate percentage of each group using mutate()
# Create percentages for white, Black, and Hispanic populations
CA_race_tract_clean <- CA_race_tract %>%
  mutate(
    pct_white = round((whiteE / total_popE) * 100, 2),
    pct_black = round((blackE / total_popE) * 100, 2),
    pct_hispanic = round((hispanicE / total_popE) * 100, 2)
  )

# Add readable tract and county name columns using str_extract() or similar
CA_race_tract_clean <- CA_race_tract_clean %>%
  mutate(
    county_fips = str_sub(GEOID, 3, 5),
    tract_code = str_sub(GEOID, 6, 11),
    county = str_remove(str_extract(NAME, ".*?County"), " County")
  )
CA_race_tract_clean %>%
  select(county, tract_code, total_popE, pct_white, pct_black, pct_hispanic) %>%
  head() %>%
  kable(digits = 1)
```

## 3.3 Demographic Analysis

**Your Task:** Analyze the demographic patterns in your selected areas.

```{r demographic-analysis}
# Find the tract with the highest percentage of Hispanic/Latino residents
# Hint: use arrange() and slice() to get the top tract
top_hispanic_tract <- CA_race_tract_clean %>%
  arrange(desc(pct_hispanic)) %>%
  slice(1) %>%
  select(county, tract_code, total_popE, pct_white, pct_black, pct_hispanic)

top_hispanic_tract %>%
  kable(
    col.names = c("County", "Tract", "Total Population", "% White", "% Black", "% Hispanic/Latino"),
    caption = "Tract with the Highest Percentage of Hispanic/Latino Residents (ACS 2022 5-year)"
  )

# Calculate average demographics by county using group_by() and summarize()
# Show: number of tracts, average percentage for each racial/ethnic group
county_demographics_summary <- CA_race_tract_clean %>%
  group_by(county) %>%
  summarize(
    tracts = n(),
    avg_pct_white = (mean(pct_white, na.rm = TRUE)),
    avg_pct_black = (mean(pct_black, na.rm = TRUE)),
    avg_pct_hispanic = (mean(pct_hispanic, na.rm = TRUE)),
    .groups = "drop"
  )
# Create a nicely formatted table of your results using kable()
county_demographics_summary %>%
  kable(
    col.names = c("County", "Number of Tracts", "Avg % White", "Avg % Black", "Avg % Hispanic/Latino"),
    caption = "Average Tract-Level Demographics by County (ACS 2022 5-year)"
  )
```

# Part 4: Comprehensive Data Quality Evaluation

## 4.1 MOE Analysis for Demographic Variables

**Your Task:** Examine margins of error for demographic variables to see if some communities have less reliable data.

**Requirements:** 
- Calculate MOE percentages for each demographic variable
- Flag tracts where any demographic variable has MOE > 15% 
- Create summary statistics

```{r demographic-moe}
# Calculate MOE percentages for white, Black, and Hispanic variables
# Hint: use the same formula as before (margin/estimate * 100)
CA_demo_moe <- CA_race_tract_clean %>%
  mutate(
    white_moe_pct = if_else(whiteE > 0, (whiteM / whiteE) * 100, NA_real_),
    black_moe_pct = if_else(blackE > 0, (blackM / blackE) * 100, NA_real_),
    hispanic_moe_pct = if_else(hispanicE > 0, (hispanicM / hispanicE) * 100, NA_real_)
  ) %>%
  mutate(
    high_demo_moe_flag = ifelse(
      white_moe_pct > 15 | black_moe_pct > 15 | hispanic_moe_pct > 15,
      TRUE, FALSE
    )
  )

demo_moe_summary <- CA_demo_moe %>%
  summarize(
    total_tracts = n(),
    tracts_with_issues = sum(high_demo_moe_flag, na.rm = TRUE),
    percent_with_issues = (tracts_with_issues / total_tracts) * 100
  )

demo_moe_summary %>% kable(caption = "Tracts with High Demographic MOE (ACS 2022 5-year)")
```

## 4.2 Pattern Analysis

**Your Task:** Investigate whether data quality problems are randomly distributed or concentrated in certain types of communities.

```{r pattern-analysis}
# Group tracts by whether they have high MOE issues
# Calculate average characteristics for each group:
# - population size, demographic percentages

# Use group_by() and summarize() to create this comparison
# Create a professional table showing the patterns

# Group tracts by whether they have high MOE issues
# (Also create a severity measure to enable comparison)
CA_demo_patterns <- CA_demo_moe %>%
  mutate(
    max_demo_moe_pct = pmax(white_moe_pct, black_moe_pct, hispanic_moe_pct, na.rm = TRUE),
    moe_severity_group = ifelse(
      max_demo_moe_pct >= median(max_demo_moe_pct, na.rm = TRUE),
      "Higher MOE Severity (>= median)",
      "Lower MOE Severity (< median)"
    )
  )

pattern_table <- CA_demo_patterns %>%
  filter(!is.na(moe_severity_group))%>%
  group_by(moe_severity_group) %>%
  summarize(
    tracts = n(),
    avg_total_pop = mean(total_popE, na.rm = TRUE),
    avg_pct_white = mean(pct_white, na.rm = TRUE),
    avg_pct_black = mean(pct_black, na.rm = TRUE),
    avg_pct_hispanic = mean(pct_hispanic, na.rm = TRUE),
    avg_max_moe_pct = mean(max_demo_moe_pct, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(percent_of_tracts = (tracts / sum(tracts)) * 100)

pattern_table %>%
  kable(caption = "Pattern Analysis by Demographic MOE Severity (ACS 2022 5-year)")
```

**Pattern Analysis:** Since almost all the tracts have issue with high MOE in their ethnic groups, I only analyzed the data quality problem within the tracts that with MOE issues because there are only 2 tracts without MOE issues and this is not representative.

I grouped g tracts with issues into higher-than-median-MOE and lower-than-median-MOE. The results show that data quality problems are not randomly distributed across communities. The higher MOE group has a slightly smaller average population than the lower MOE group. The average White percentage is almost the same in both groups, while the lower MOE group has a higher average Hispanic percentage and a higher average Black percentage. One tract has missing demographic MOE values due to zero population and was excluded from the pattern analysis.

# Part 5: Policy Recommendations

## 5.1 Analysis Integration and Professional Summary

**Your Task:** Write an executive summary that integrates findings from
all four analyses.

**Executive Summary Requirements:** 

1. **Overall Pattern
Identification**: What are the systematic patterns across all your
analyses? 

2. **Equity Assessment**: Which communities face the greatest
risk of algorithmic bias based on your findings? 

3. **Root Cause Analysis**: What underlying factors drive both data quality issues and bias risk? 

4. **Strategic Recommendations**: What should the Department
implement to address these systematic issues?

**Executive Summary:**

Overall, the pattern suggests that data quality issues vary in geographic scales. At the county level, most counties show reliable median income estimates, but some rural counties have much higher margins of error. At the tract level, demographic data show very high MOE values in almost all tracts. When tracts are grouped by MOE severity, higher uncertainty is more common in smaller population tracts, which shows that data quality problems are not randomly
distributed.

Rural counties and small tracts face the biggest risk of uncertainty from algorithms. If algorithms use this data without fixing it first, these communities might get unfair decisions about resources. This creates more harm in places that already get less attention.

The main cause of data quality issues is the use of survey-based data at very small geographic scales. The American Community Survey relies on samples, and sample sizes become very small at the tract level, especially for specific racial or ethnic groups. When population counts are low, margins of error become large, which increases uncertainty.

The Department should use different approaches for different data quality levels. Areas with low MOE data can use regular algorithms. Areas with moderate MOE data should use algorithms carefully with extra reviews. Areas with high MOE data should rely on additional data sources or manual review of data quality and bias.

## 6.3 Specific Recommendations

**Your Task:** Create a decision framework for algorithm implementation.

```{r recommendations-data}
# Create a summary table with county reliability information
recommendations <- CA_data_quality %>%
  select(
    county,
    median_hh_incomeE,
    income_moe_pct,
    income_reliability
  ) %>%
# Add a new column with algorithm recommendations using case_when(): 
# - High Confidence: "Safe for algorithmic decisions" 
# - Moderate Confidence: "Use with caution - monitor outcomes" 
# - Low Confidence: "Requires manual review or additional data"
  mutate(
    algorithm_recommendation = case_when(
      income_reliability == "High Confidence" ~ "Safe for algorithmic decisions",
      income_reliability == "Moderate Confidence" ~ "Use with caution - monitor outcomes",
      income_reliability == "Low Confidence" ~ "Requires manual review or additional data",
      TRUE ~ NA_character_
    )
  )

# Format as a professional table
recommendations %>%
  kable(
    col.names = c("County", "Median Income", "MOE (%)", "Reliability Category", "Algorithm Recommendation"),
    caption = "Decision Framework for Algorithm Implementation (ACS 2022 5-year)"
  )

```

**Key Recommendations:**

**Your Task:** Use your analysis results to provide specific guidance to the department.

```{r}
high_conf_counties <- recommendations_table %>%
  filter(income_reliability == "High Confidence") %>%
  arrange(income_moe_pct) %>%
  pull(county)
high_conf_counties_text <- paste(high_conf_counties, collapse = ", ")
```

1.  **Counties suitable for immediate algorithmic implementation:**
    Los Angeles, Orange, Sacramento, Santa Clara, Alameda, San Diego, San Bernardino, Contra Costa, Riverside, Fresno, San Francisco, Ventura, Placer, San Joaquin, San Mateo, Solano, Stanislaus, Sonoma, Santa Barbara, Kern, Monterey, Tulare, San Luis Obispo, Yolo, Napa, Marin, Santa Cruz, Kings, Merced, El Dorado, Butte, Mendocino, Shasta, Humboldt, Madera, Imperial, Yuba, Lake, Sutter, Nevada, Siskiyou, Calaveras
    
```{r}
moderate_conf_counties <- recommendations_table %>%
  filter(income_reliability == "Moderate Confidence") %>%
  arrange(income_moe_pct) %>%
  pull(county)
moderate_conf_counties_text <- paste(moderate_conf_counties, collapse = ", ")
```

2.  **Counties requiring additional oversight:** 
San Benito, Lassen, Glenn, Tuolumne, Tehama, Del Norte, Amador, Colusa, Inyo, Mariposa, Modoc

```{r}
low_conf_counties <- recommendations_table %>%
  filter(income_reliability == "Low Confidence") %>%
  arrange(desc(income_moe_pct)) %>%
  pull(county)
low_conf_counties_text <- paste(low_conf_counties, collapse = ", ")
```

3.  **Counties needing alternative approaches:** 
Mono, Alpine, Sierra, Trinity, Plumas

## Questions for Further Investigation

1. Do MOE values show spatial clustering when measured with Moranâ€™s I, or are high and low MOE tracts randomly distributed?

2. Are data quality problems related to other community characteristics, such as immigrant population?

# Technical Notes

**Data Sources:** - U.S. Census Bureau, American Community Survey 2018-2022 5-Year Estimates - Retrieved via tidycensus R package on 2/2/2026

**Reproducibility:** - All analysis conducted in R version 4.3.1 - Census API key required for replication - Complete code and documentation available at: https://vrnczay.github.io/CPLN-5920-Portfolio/

**Methodology Notes:** I used ACS 2022 five year estimates at the county level to compare median household income reliability, and I calculated MOE percent as MOE divided by estimate times 100. I created reliability categories based on MOE percent and used these categories to guide the county level interpretation.

For the tract level study, I randomly selected one county from each reliability category and used set.seed so the selection stayed the same every time I ran the code. This may affect reproductivity when other people use my code since they may not randomly generate the same county as mine.

**Limitations:** ACS data are survey estimates, so uncertainty can be high, especially at the tract level and for smaller racial or ethnic groups. Almost all tracts had high MOE values for at least one groups, so comparison between tracts with MOE issue and without is unrealistic in CA. So, I used MOE severity groups instead. 

This analysis only covers California and one ACS time period, so the findings may not generalize to other states or years.

The results also depend on the given thresholds for reliability categories.

------------------------------------------------------------------------

## Submission Checklist

Before submitting your portfolio link on Canvas:

-   [ ] All code chunks run without errors
-   [ ] All "[Fill this in]" prompts have been completed
-   [ ] Tables are properly formatted and readable
-   [ ] Executive summary addresses all four required components
-   [ ] Portfolio navigation includes this assignment
-   [ ] Census API key is properly set
-   [ ] Document renders correctly to HTML

**Remember:** Submit your portfolio URL on Canvas, not the file itself. Your assignment should be accessible at
`your-portfolio-url/labs/lab_1/your_file_name.html`
